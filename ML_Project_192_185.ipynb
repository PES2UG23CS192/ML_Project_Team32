{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-p91Tuh3Z74",
        "outputId": "43b13a56-a172-497e-e5d0-3d3addeefec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Part 1 — Setup & Library Installation\n",
        "# ==========================================\n",
        "!pip install torch torchvision pytorch-fid --quiet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "from pytorch_fid import fid_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Set device (GPU preferred)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Part 2 — Load Dataset (CIFAR-10)\n",
        "# ==========================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize between -1 and 1\n",
        "])\n",
        "\n",
        "dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWflplly3uiI",
        "outputId": "4b0c0f81-5d77-43dc-a00f-1d86a5b77ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [04:16<00:00, 665kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Part 3 — Define Generator & Discriminator\n",
        "# ==========================================\n",
        "latent_dim = 100  # Random noise vector size\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img).view(-1, 1).squeeze(1)\n",
        "\n",
        "\n",
        "# Initialize networks\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "# Loss and Optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n"
      ],
      "metadata": {
        "id": "-N6a-vLZ3u7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Part 4 — Define Correlation-Aware Loss\n",
        "# ==========================================\n",
        "def correlation_loss(fake_imgs):\n",
        "    # Flatten each image and normalize\n",
        "    x = fake_imgs.view(fake_imgs.size(0), -1)\n",
        "    x = (x - x.mean(dim=1, keepdim=True)) / (x.std(dim=1, keepdim=True) + 1e-6)\n",
        "\n",
        "    # Compute pairwise correlation\n",
        "    corr = torch.mm(x, x.t()) / x.size(1)\n",
        "    I = torch.eye(corr.size(0), device=corr.device)\n",
        "\n",
        "    # Encourage correlation matrix to be close to identity (diverse outputs)\n",
        "    return ((corr - I) ** 2).mean()\n"
      ],
      "metadata": {
        "id": "QEmn4fBt39GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Part 5 — Training Loop\n",
        "# ==========================================\n",
        "epochs = 50\n",
        "fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "        real_imgs = imgs.to(device)\n",
        "        valid = torch.ones(imgs.size(0), device=device)\n",
        "        fake = torch.zeros(imgs.size(0), device=device)\n",
        "\n",
        "        # ---------------------\n",
        "        # Train Generator\n",
        "        # ---------------------\n",
        "        optimizer_G.zero_grad()\n",
        "        z = torch.randn(imgs.size(0), latent_dim, 1, 1, device=device)\n",
        "        gen_imgs = G(z)\n",
        "\n",
        "        g_loss_basic = criterion(D(gen_imgs), valid)\n",
        "        g_corr_loss = correlation_loss(gen_imgs)\n",
        "        g_loss = g_loss_basic + 0.05 * g_corr_loss  # Weighted term\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        # Train Discriminator\n",
        "        # ---------------------\n",
        "        optimizer_D.zero_grad()\n",
        "        real_loss = criterion(D(real_imgs), valid)\n",
        "        fake_loss = criterion(D(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "    print(f\"[Epoch {epoch+1}/{epochs}] D_loss: {d_loss.item():.4f} | G_loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        save_image(gen_imgs[:25], f\"images/epoch_{epoch+1}.png\", nrow=5, normalize=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkv7VaZD39NQ",
        "outputId": "44a9c5a4-3ccd-421b-c3b9-1286230a1906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/50] D_loss: 0.6455 | G_loss: 5.0553\n",
            "[Epoch 2/50] D_loss: 0.2388 | G_loss: 3.5971\n",
            "[Epoch 3/50] D_loss: 0.3389 | G_loss: 1.1971\n",
            "[Epoch 4/50] D_loss: 0.4280 | G_loss: 6.6910\n",
            "[Epoch 5/50] D_loss: 0.1395 | G_loss: 3.2892\n",
            "[Epoch 6/50] D_loss: 0.2975 | G_loss: 1.9846\n",
            "[Epoch 7/50] D_loss: 0.1725 | G_loss: 2.5716\n",
            "[Epoch 8/50] D_loss: 0.4814 | G_loss: 0.9235\n",
            "[Epoch 9/50] D_loss: 0.4283 | G_loss: 1.0941\n",
            "[Epoch 10/50] D_loss: 0.1582 | G_loss: 2.7194\n",
            "[Epoch 11/50] D_loss: 0.3171 | G_loss: 2.9810\n",
            "[Epoch 12/50] D_loss: 0.2944 | G_loss: 1.3553\n",
            "[Epoch 13/50] D_loss: 0.2620 | G_loss: 1.7591\n",
            "[Epoch 14/50] D_loss: 0.4005 | G_loss: 2.2762\n",
            "[Epoch 15/50] D_loss: 0.0816 | G_loss: 4.1221\n",
            "[Epoch 16/50] D_loss: 0.3336 | G_loss: 3.2927\n",
            "[Epoch 17/50] D_loss: 0.1588 | G_loss: 2.6374\n",
            "[Epoch 18/50] D_loss: 0.1707 | G_loss: 2.2686\n",
            "[Epoch 19/50] D_loss: 0.1714 | G_loss: 2.6263\n",
            "[Epoch 20/50] D_loss: 0.1128 | G_loss: 2.7987\n",
            "[Epoch 21/50] D_loss: 0.1154 | G_loss: 3.6339\n",
            "[Epoch 22/50] D_loss: 0.0993 | G_loss: 3.2967\n",
            "[Epoch 23/50] D_loss: 0.2197 | G_loss: 1.6307\n",
            "[Epoch 24/50] D_loss: 0.1138 | G_loss: 2.1047\n",
            "[Epoch 25/50] D_loss: 0.0989 | G_loss: 2.4623\n",
            "[Epoch 26/50] D_loss: 0.1147 | G_loss: 4.3076\n",
            "[Epoch 27/50] D_loss: 0.0727 | G_loss: 3.4401\n",
            "[Epoch 28/50] D_loss: 0.0654 | G_loss: 2.9584\n",
            "[Epoch 29/50] D_loss: 0.1004 | G_loss: 2.7426\n",
            "[Epoch 30/50] D_loss: 0.0561 | G_loss: 3.4602\n",
            "[Epoch 31/50] D_loss: 0.3019 | G_loss: 4.0301\n",
            "[Epoch 32/50] D_loss: 0.2709 | G_loss: 1.3868\n",
            "[Epoch 33/50] D_loss: 0.3107 | G_loss: 2.1969\n",
            "[Epoch 34/50] D_loss: 0.0483 | G_loss: 3.7422\n",
            "[Epoch 35/50] D_loss: 0.1355 | G_loss: 2.1252\n",
            "[Epoch 36/50] D_loss: 0.1050 | G_loss: 2.2857\n",
            "[Epoch 37/50] D_loss: 0.3950 | G_loss: 1.0856\n",
            "[Epoch 38/50] D_loss: 0.0705 | G_loss: 3.1444\n",
            "[Epoch 39/50] D_loss: 0.0653 | G_loss: 4.2433\n",
            "[Epoch 40/50] D_loss: 0.0821 | G_loss: 2.7751\n",
            "[Epoch 41/50] D_loss: 0.0557 | G_loss: 5.9943\n",
            "[Epoch 42/50] D_loss: 0.2361 | G_loss: 2.2019\n",
            "[Epoch 43/50] D_loss: 0.0809 | G_loss: 2.9262\n",
            "[Epoch 44/50] D_loss: 0.0682 | G_loss: 3.4907\n",
            "[Epoch 45/50] D_loss: 0.1439 | G_loss: 2.3035\n",
            "[Epoch 46/50] D_loss: 0.0350 | G_loss: 3.5782\n",
            "[Epoch 47/50] D_loss: 0.0812 | G_loss: 2.8708\n",
            "[Epoch 48/50] D_loss: 0.0378 | G_loss: 3.9071\n",
            "[Epoch 49/50] D_loss: 0.0450 | G_loss: 3.5580\n",
            "[Epoch 50/50] D_loss: 0.0614 | G_loss: 3.5470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Part 6 — Evaluate FID (Fixed Version)\n",
        "# ==========================================\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Create directory for generated images\n",
        "os.makedirs(\"generated\", exist_ok=True)\n",
        "G.eval()\n",
        "\n",
        "# Generate around 10,000 fake images for stable FID\n",
        "num_images = 10000\n",
        "batch_size_gen = 128\n",
        "\n",
        "print(\"Generating fake images for FID evaluation...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    for i in tqdm(range(num_images // batch_size_gen)):\n",
        "        z = torch.randn(batch_size_gen, latent_dim, 1, 1, device=device)\n",
        "        gen_imgs = G(z)\n",
        "        for j, img in enumerate(gen_imgs):\n",
        "            idx = i * batch_size_gen + j\n",
        "            save_image(img, f\"generated/{idx}.png\", normalize=True)\n",
        "            total += 1\n",
        "\n",
        "print(f\"✅ Generated {total} fake images in 'generated/'\")\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# Check folder contents and real data path\n",
        "# -----------------------------------------------------\n",
        "real_path = \"./data/cifar10_real\"\n",
        "fake_path = \"./generated\"\n",
        "\n",
        "# Save a few real CIFAR-10 samples to a folder for FID comparison\n",
        "os.makedirs(real_path, exist_ok=True)\n",
        "if len(glob.glob(f\"{real_path}/*.png\")) < 1000:\n",
        "    print(\"Preparing real CIFAR-10 images...\")\n",
        "    for idx, (imgs, _) in enumerate(dataloader):\n",
        "        for j, img in enumerate(imgs):\n",
        "            save_image(img, f\"{real_path}/{idx*len(imgs)+j}.png\", normalize=True)\n",
        "        if idx > 80:  # around 10k samples\n",
        "            break\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# Compute FID between real and fake\n",
        "# -----------------------------------------------------\n",
        "fid_value = fid_score.calculate_fid_given_paths(\n",
        "    [real_path, fake_path],\n",
        "    batch_size=64,\n",
        "    device=device,\n",
        "    dims=2048\n",
        ")\n",
        "\n",
        "print(f\"\\n✅ Final FID Score: {fid_value:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRbJMK_a4AyT",
        "outputId": "d2d1fe98-3f70-4a1f-f1e1-89d445b4b499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating fake images for FID evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 78/78 [00:10<00:00,  7.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated 9984 fake images in 'generated/'\n",
            "Preparing real CIFAR-10 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 164/164 [00:41<00:00,  3.95it/s]\n",
            "100%|██████████| 1000/1000 [04:01<00:00,  4.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Final FID Score: 44.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "82HEilAW4A7s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}